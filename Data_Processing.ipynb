{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from txt file.\n",
    "Files can be accessed from OR library, [OR Library](http://people.brunel.ac.uk/~mastjjb/jeb/info.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data from txt files to JSON \n",
    "items with dimensions,volume,value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "#* output file will containe an instance of problem set\n",
    "\n",
    "import json\n",
    "import random,math\n",
    "# Open the file in read mode ('r')\n",
    "\n",
    "input_file ='DataSets/RawTxt/wtpack/wtpack'\n",
    "output_file ='DataSets/processed/P_Instances/wtpack'\n",
    "box_types = [\"3 \",\"5 \",\"8 \",\"10 \",\"12 \",\"15 \" ,\"20 \"]\n",
    "box_per_customer = [300,500,800,1000,1200,1500,2000]\n",
    "MIN_VALUE = 50\n",
    "MAX_VALUE = 500\n",
    "\n",
    "for i in range(1,8):\n",
    "    dataset = {}\n",
    "    index = 0\n",
    "    counter = 0\n",
    "    with open(f'{input_file}{i}.txt', 'r') as file:\n",
    "        # Initialize a variable to store the lines you want to keep\n",
    "        lines_to_keep = []\n",
    "        data = []\n",
    "        # Iterate through each line in the file\n",
    "        for line in file:\n",
    "            # Skip lines you want to ignore\n",
    "            line =line.strip()\n",
    "            if ( line.startswith(\"587\") or line.startswith(box_types[i-1])):\n",
    "                continue\n",
    "\n",
    "            # Append the lines you want to keep\n",
    "   \n",
    "            lines_to_keep.append(line.strip())\n",
    "            counter +=1\n",
    "\n",
    "            if counter == int(box_types[i-1]):\n",
    "                item =1\n",
    "                for j in lines_to_keep:\n",
    "                    \n",
    "                    j=j.strip().split()\n",
    "                    temp=[int(j[0]),int(j[2]),int(j[4]), (int(j[0])*int(j[2])*int(j[4])),\n",
    "                                    random.randint(MIN_VALUE, MAX_VALUE)]\n",
    "                    temp=[temp]*int(j[6])\n",
    "                    dataset[\"total orders\"]=len(dataset)\n",
    "                    if len(dataset) == 0 or f\"Order_{index}\" not in dataset:\n",
    "                        dataset[f\"Order_{index}\"] = {\n",
    "                                        'truck dimension': [589,235,239], \"unique_items\":int(box_types[i-1]),\n",
    "                                        f'item{item}':{\"quantity\":len(temp), \"boxes\":temp,\n",
    "                                                       \"total value\": sum(i[-1] for i in temp)}\n",
    "                                        }\n",
    "                        item +=1\n",
    "                    else:\n",
    "                        dataset[f\"Order_{index}\"][f'item{item}']={\n",
    "                                        \"quantity\": len(temp),'boxes':temp,\n",
    "                                        \"total value\": sum(i[-1] for i in temp)\n",
    "                                        }\n",
    "                        item +=1\n",
    "                #dataset[index]= [box for item in data for box in item]\n",
    "                index +=1\n",
    "                counter = 0\n",
    "                data.clear()\n",
    "                lines_to_keep.clear()\n",
    "   \n",
    "    with open(f'{output_file}{i}.json', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contains all fields from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random,math,copy\n",
    "# Open the file in read mode ('r')\n",
    "\n",
    "input_file ='DataSets/RawTxt/wtpack/wtpack'\n",
    "output_file ='DataSets/processed/P_Instances/wtpack'\n",
    "box_types = [\"3 \",\"5 \",\"8 \",\"10 \",\"12 \",\"15 \" ,\"20 \"]\n",
    "box_per_customer = [300,500,800,1000,1200,1500,2000]\n",
    "MIN_VALUE = 50\n",
    "MAX_VALUE = 500\n",
    "\n",
    "for i in range(1,8):\n",
    "    dataset = {}\n",
    "    index = 0\n",
    "    counter = 0\n",
    "    with open(f'{input_file}{i}.txt', 'r') as file:\n",
    "        # Initialize a variable to store the lines you want to keep\n",
    "        lines_to_keep = []\n",
    "        data = []\n",
    "        # Iterate through each line in the file\n",
    "        for line in file:\n",
    "            # Skip lines you want to ignore\n",
    "            data.clear()\n",
    "            line =line.strip()\n",
    "            if ( line.startswith(\"587\") or line.startswith(box_types[i-1])):\n",
    "                continue\n",
    "\n",
    "            # Append the lines you want to keep\n",
    "   \n",
    "            lines_to_keep.append(line.strip())\n",
    "            counter +=1\n",
    "\n",
    "            if counter == int(box_types[i-1]):\n",
    "                item =1\n",
    "                for j in lines_to_keep:\n",
    "                    \n",
    "                    j=j.strip().split()\n",
    "                    temp=[int(j[0]),int(j[1]),int(j[2]),int(j[3]),int(j[4]),int(j[5]),int(j[6]),\n",
    "                           (int(j[0])*int(j[2])*int(j[4])),float(j[8]),float(j[10]),float(j[10])]\n",
    "                    data.append(temp)\n",
    "                dataset[\"total Instances\"]=len(dataset)\n",
    "                if f\"{index}\" not in dataset:\n",
    "                    dataset[f\"{index}\"] = {\n",
    "                                    'truck dimension': [589,235,239],\n",
    "                                    \"unique_items\":int(box_types[i-1]),\n",
    "                                    f'instance{index}':copy.deepcopy(data)\n",
    "                                    }\n",
    "\n",
    "\n",
    "            #dataset[index]= [box for item in data for box in item]\n",
    "                index +=1\n",
    "                counter = 0\n",
    "                \n",
    "                lines_to_keep.clear()\n",
    "   \n",
    "    with open(f'{output_file}{i}.json', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data from JSON files\n",
    "Randomly Assigning orders to customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random,math,copy\n",
    "# Open the file in read mode ('r')\n",
    "\n",
    "input_file ='DataSets/processed/wtpackComplete/wtpack1.json'\n",
    "output_file ='DataSets/processed/Updated/wtpack1.json'\n",
    "dataset={}\n",
    "boxes = []\n",
    "# boxes_per_customer = \n",
    "with open(input_file, 'r') as file:\n",
    "\n",
    "    data = json.load(file)\n",
    "\n",
    "for key in data.keys():\n",
    "    boxes.extend(data.get(key).get('item1').get('boxes'))\n",
    "    boxes.extend(data.get(key).get('item2').get('boxes'))\n",
    "    boxes.extend(data.get(key).get('item3').get('boxes'))\n",
    "    total_boxes =data.get(key).get('item1').get('quantity')+data.get(key).get('item3').get('quantity')+data.get(key).get('item2').get('quantity')\n",
    "    \n",
    "    customer =1\n",
    "    # boxes = sorted(boxes,key=lambda xx: xx[3],reverse=True )\n",
    "    #for i in range(1,4): \n",
    "    dataset[key.split(\"_\")[1]] = {'truck dimension': data[key]['truck dimension']}\n",
    "    dataset[key.split(\"_\")[1]][\"customer1\"] = [item+[1] for item in random.sample(boxes, 35)]#[boxes[random.randint(0, total_boxes // 3)] for _ in range(total_boxes)]\n",
    "    dataset[key.split(\"_\")[1]][\"customer2\"] = [item+[2] for item in random.sample(boxes, 35)]#[boxes[random.randint(0, total_boxes // 3)] for _ in range(total_boxes)]\n",
    "    dataset[key.split(\"_\")[1]][\"customer3\"] = [item+[3] for item in random.sample(boxes, 40)]#[boxes[random.randint(0, total_boxes // 3)] for _ in range(total_boxes)]\n",
    "                    \n",
    "                        \n",
    "                        # 'boxes':sorted(data[f'item{j}']['boxes'],\n",
    "                        #                 key=lambda xx: xx[3],reverse=True),\n",
    "                        # 'total value': sum(i[-1] for i in data[f'item{j}']['boxes']),\n",
    "                        # \"customer\" : customer,#random.randint(1, 3),\n",
    "                        # \"order_priority\" : random.randint(1, 3)}\n",
    "        #dataset[j][\"number\"] = data[f'item{j}']['quantity']\n",
    "        #i += 1   \n",
    "with open(f'{output_file}', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mboxes\u001b[49m\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     17\u001b[0m     boxes\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     18\u001b[0m     boxes\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mboxes\u001b[49m\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     17\u001b[0m     boxes\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     18\u001b[0m     boxes\u001b[38;5;241m.\u001b[39mextend(data\u001b[38;5;241m.\u001b[39mget(key)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\elahi\\Desktop\\AIDEAS_Local\\CLP\\env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elahi\\Desktop\\AIDEAS_Local\\CLP\\env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#! Forgot what am i planning to do\n",
    "\n",
    "import json\n",
    "import random,math,copy\n",
    "# Open the file in read mode ('r')\n",
    "\n",
    "for i in range(2,8):\n",
    "    input_file = f\"DataSets/processed/wtpackComplete/wtpack{i}.json\"\n",
    "    output_file = f'DataSets/processed/Updated/wtpack{i}.json'\n",
    "    dataset={}\n",
    "    boxes = []\n",
    "    # boxes_per_customer = \n",
    "    with open(input_file, 'r') as file:\n",
    "\n",
    "        data = json.load(file)\n",
    "\n",
    "    for key in data.keys():\n",
    "        dataset[key.split(\"_\")[1]] = {'truck dimension': data[key]['truck dimension']}\n",
    "        for i in range(data.get(key).get(\"unique_items\")+1):\n",
    "            boxes.extend(data.get(key).get(f'item{i}').get('boxes'))\n",
    "            # boxes.extend(data.get(key).get('item2').get('boxes'))\n",
    "            # boxes.extend(data.get(key).get('item3').get('boxes'))\n",
    "            total_boxes += data.get(key).get(f'item{i}').get('quantity')\n",
    "            #+data.get(key).get('item3').get('quantity')+data.get(key).get('item2').get('quantity')\n",
    "    \n",
    "    with open(f'{output_file}', 'w') as outfile:\n",
    "        json.dump(dataset, outfile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Changing sorting variables in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_boxes.extend(sorted([tup for tup in tt if tup[0][-1] in {1}],\n",
    "#                             key=lambda x: x[0][3], reverse=True))\n",
    "# sorted_boxes.extend(sorted([tup for tup in tt if tup[0][-1] in {2}],\n",
    "#                             key=lambda x: x[0][3], reverse=True))\n",
    "# sorted_boxes.extend(sorted([tup for tup in tt if tup[0][-1] in {3}],\n",
    "#                             key=lambda x: x[0][3], reverse=True))\n",
    "from box import Item\n",
    "from container import Container\n",
    "from helper import *\n",
    "from copy import deepcopy\n",
    "import population as geni\n",
    "from fitnesscalc import*\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "ROTATIONS = 6\n",
    "NUM_OF_INDIVIDUALS = 36\n",
    "input_file = 'DataSets/processed/Updated/wtpack1.json'\n",
    "\n",
    "with open(input_file, 'r') as outfile:\n",
    "    data = json.load(outfile)\n",
    "problem_indices = list(data.keys())\n",
    "boxes = []\n",
    "temp_boxes = []\n",
    "for p_ind in problem_indices:\n",
    "    if int(p_ind) >= 1:\n",
    "        continue\n",
    "    temp_boxes.extend(data[p_ind][\"customer1\"])\n",
    "    temp_boxes.extend(data[p_ind][\"customer2\"])\n",
    "    temp_boxes.extend(data[p_ind][\"customer3\"])\n",
    "max_weight = 28080\n",
    "CONT = Container(\n",
    "    name=f\"ISO-20 feet Dry Container_{p_ind}\",\n",
    "    LWH=data[p_ind]['truck dimension'],\n",
    "    max_weight=28080\n",
    ")\n",
    "print(CONT.string())\n",
    "# Extracting inputs from the json file\n",
    "# * instentiating item objects\n",
    "for i in range(len(temp_boxes)):\n",
    "    box = temp_boxes[i]\n",
    "    boxes.append(Item(\n",
    "        partno=f\"Box-{i+1}\",\n",
    "        name=f\"C-{box[-1]}\",\n",
    "        weight=box[3],\n",
    "        LWH=box[0:3],\n",
    "        rotation=0,\n",
    "        value=box[4]\n",
    "    ))\n",
    "CONT.items.extend(boxes)\n",
    "total_value = sum(i.value for i in boxes)\n",
    "box_params = {}\n",
    "for index in range(len(boxes)):\n",
    "    box_params[index] = boxes[index]\n",
    "population = geni.generate_pop(box_params, NUM_OF_INDIVIDUALS, ROTATIONS)\n",
    "\n",
    "# evaluate(population, CONT, box_params, total_value, support_ratio=0.70)\n",
    "for key, individual in population.items():\n",
    "\n",
    "        print(f\"processing key.....{key}\")\n",
    "        occupied_vol = 0\n",
    "        number_boxes = 0\n",
    "        value = 0\n",
    "        result = []\n",
    "        # copying placement points a list [[0,0,0]]\n",
    "        PP = copy.deepcopy(CONT.PP)\n",
    "        # * boxes =  copy.deepcopy( box_params)\n",
    "        items = [(copy.deepcopy( box_params)[box_number], r)\n",
    "                 for box_number, r in zip(individual['order'], individual['rotate'])]\n",
    "        \n",
    "        for i in range(3,0,-1):    \n",
    "            \n",
    "            result.extend(sorted([tup for tup in items if tup[0].name in {f\"C-{i}\"}],\n",
    "                            key=lambda x: (-x[0].get_volume(), x[1])))\n",
    "            for i,r in result:\n",
    "                pprint(f\"{i.get_id()},{i.get_volume()},{i.get_dimention()},{r}\")#,x[0].get_dimention()[0]\n",
    "        boxes = sorted(items, key=lambda item: (item[0].get_volume(), item[0].get_dimention()[0]), reverse=True)  # ,item[2],item[1]\n",
    "        boxes = sorted(boxes, key=lambda item: (item[0].get_id().split(\"C-\")[1]), reverse=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Changing sorting variables in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding a way to distribute items among customers evenly at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the average number of boxes per customer\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m num_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m num_customers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# This value can be entered by the user on the UI\u001b[39;00m\n\u001b[0;32m     16\u001b[0m avg_boxes_per_customer \u001b[38;5;241m=\u001b[39m num_boxes \u001b[38;5;241m/\u001b[39m num_customers\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the average number of boxes per customer\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m num_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     15\u001b[0m num_customers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# This value can be entered by the user on the UI\u001b[39;00m\n\u001b[0;32m     16\u001b[0m avg_boxes_per_customer \u001b[38;5;241m=\u001b[39m num_boxes \u001b[38;5;241m/\u001b[39m num_customers\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the average number of boxes per customer\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m num_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28msum\u001b[39m(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data[key]\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     15\u001b[0m num_customers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# This value can be entered by the user on the UI\u001b[39;00m\n\u001b[0;32m     16\u001b[0m avg_boxes_per_customer \u001b[38;5;241m=\u001b[39m num_boxes \u001b[38;5;241m/\u001b[39m num_customers\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import math\n",
    "\n",
    "input_file ='DataSets/processed/wtpackComplete/wtpack1.json'\n",
    "output_file ='DataSets/processed/Updated/wtpack_1.json'\n",
    "dataset={}\n",
    "boxes = []\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Calculate the average number of boxes per customer\n",
    "num_boxes = sum(sum(item['boxes'] for item in data[key].values()) for key in data.keys())\n",
    "num_customers = 3  # This value can be entered by the user on the UI\n",
    "avg_boxes_per_customer = num_boxes / num_customers\n",
    "\n",
    "# Calculate the quotient and remainder of the division\n",
    "quotient, remainder = math.modf(avg_boxes_per_customer * num_customers)\n",
    "\n",
    "# Assign the quotient to each customer\n",
    "boxes_per_customer = [quotient for _ in range(num_customers)]\n",
    "\n",
    "# Distribute the remainder randomly among the customers\n",
    "for i in range(remainder):\n",
    "    boxes_per_customer[random.randint(0, num_customers - 1)] += 1\n",
    "\n",
    "# Assign boxes to each customer\n",
    "for key in data.keys():\n",
    "    customer_boxes = []\n",
    "    for item in data[key].values():\n",
    "        customer_boxes.extend(item['boxes'])\n",
    "    random.shuffle(customer_boxes)\n",
    "    for i, customer in enumerate(boxes_per_customer):\n",
    "        dataset[key.split(\"_\")[1]] = {'truck dimension': data[key]['truck dimension']}\n",
    "        dataset[key.split(\"_\")[1]][f'customer{i+1}'] = customer_boxes[:customer]\n",
    "        customer_boxes = customer_boxes[customer:]\n",
    "\n",
    "# Write the dataset to the output file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(dataset, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
